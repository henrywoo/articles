# Hadoop 2


## Hadoop

- stable for production: v 2.8.5

```
13:09 # ll /opt/share/software/HadoopEcosystem/hadoop/
total 212
drwxr-xr-x 10 libvirt-qemu henry   4096 Jan  9 16:14 ./
drwxrwxr-x 14 libvirt-qemu henry   4096 Jan 15 04:28 ../
drwxr-xr-x  2 libvirt-qemu henry   4096 Aug  1 22:05 bin/
drwxr-xr-x  3 libvirt-qemu henry   4096 Aug  1 21:28 etc/
drwxr-xr-x  2 libvirt-qemu henry   4096 Aug  1 22:05 include/
drwxr-xr-x  3 libvirt-qemu henry   4096 Aug  1 22:05 lib/
drwxr-xr-x  4 libvirt-qemu henry   4096 Aug  1 22:05 libexec/
-rw-r--r--  1 libvirt-qemu henry 147144 Jul 28 16:13 LICENSE.txt
drwxrwxr-x  3 libvirt-qemu henry   4096 Jan  9 16:38 logs/
-rw-r--r--  1 libvirt-qemu henry  21867 Jul 28 16:13 NOTICE.txt
-rw-r--r--  1 libvirt-qemu henry   1366 Jul 28 13:41 README.txt
drwxr-xr-x  3 libvirt-qemu henry   4096 Aug  1 21:28 sbin/
drwxr-xr-x  4 libvirt-qemu henry   4096 Aug  1 22:17 share/
```

name node: u3  
data node: u4,u5,u6,uu

### prepare for hadoop folders

- Hadoop 285

```bash
export HADOOP_DEPLOY_ROOT=/opt/hadoop285
sss 2
for i in `seq 3 6` u; do
  ansible u$i -a "rm -fr $HADOOP_DEPLOY_ROOT";
done

for i in `seq 3 6` u; do
ansible u$i -a "mkdir -p $HADOOP_DEPLOY_ROOT/data";
ansible u$i -a "mkdir -p $HADOOP_DEPLOY_ROOT/pid";
ansible u$i -a "mkdir -p $HADOOP_DEPLOY_ROOT/log";
ansible u$i -a "mkdir -p $HADOOP_DEPLOY_ROOT/tmp";
ansible u$i -a "mkdir -p $HADOOP_DEPLOY_ROOT/mr-history/tmp";
ansible u$i -a "mkdir -p $HADOOP_DEPLOY_ROOT/mr-history/done";
done

ansible u3 -a "mkdir -p $HADOOP_DEPLOY_ROOT/name";
```

at ~/.bashrc

```bash
# also hadoop-env.sh
export HADOOP_DEPLOY_ROOT=/opt/hadoop285
export HADOOP_HOME=/opt/share/software/HadoopEcosystem/hadoop

export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export HADOOP_PID_DIR=$HADOOP_DEPLOY_ROOT/pid
export HADOOP_LOG_DIR=$HADOOP_DEPLOY_ROOT/log

export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
# required by spark
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-/etc/hadoop/conf}
# WARNING: YARN_CONF_DIR has been replaced by HADOOP_CONF_DIR. Using value of YARN_CONF_DIR.
#export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop
export YARN_RESOURCEMANAGER_USER="root"
export YARN_NODEMANAGER_USER="root"

# yarn-env.sh
export HADOOP_DEPLOY_ROOT=/opt/hadoop285
export YARN_LOG_DIR=$HADOOP_DEPLOY_ROOT/log
```

https://stackoverflow.com/questions/22332760/how-can-i-specify-hadoop-xml-configuration-variables-via-the-hadoop-shell-script

HDFS: [http://u3:2850](http://u3:2850)  
cluster: [http://u3:7088](http://u3:7088)  
history: [http://u3:19888](http://u3:19888)

### init namenode

```
ssh u3
$hdfs namenode -format
```

### start or stop hadoop cluster

Start:   

```bash
for i in `seq 3 6`; do virsh start u$i; done
sleep 60 # wait for 60 secs for servers to boot up
ansible u3 -a "start-all.sh";
ansible u3 -a "mapred historyserver &";
```

Stop:  
```bash
ansible u3 -a "killall JobHistoryServer";
ansible u3 -a "stop-all.sh";
for i in `seq 3 6`; do virsh shutdown u$i; done
```

HDFS: [http://u3:2850](http://u3:2850)  
![](img/hadoop.gif)

cluster: [http://u3:7088](http://u3:7088)  
![](img/Selection_004.png)

